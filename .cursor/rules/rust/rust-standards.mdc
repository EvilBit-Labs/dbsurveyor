---
globs: **/*.rs,**/Cargo.toml,**/Cargo.lock
alwaysApply: false
---

# Rust Development Standards for DBSurveyor

## Rust Version Requirements

- **Minimum Rust Version**: 1.77+ (as specified in workspace Cargo.toml)
- **Edition**: 2021
- **Toolchain**: Stable channel preferred

## Code Quality Standards

### Formatting and Linting

- **Formatting**: `cargo fmt` with default settings (4-space indentation)
- **Linting**: `cargo clippy -- -D warnings` - ZERO warnings policy enforced
- **Security**: `unsafe` code is denied at workspace level
- **Documentation**: All public items must have `///` doc comments

### Naming Conventions

- **Functions/Variables**: `snake_case`
- **Types/Structs/Enums**: `PascalCase`
- **Constants**: `SCREAMING_SNAKE_CASE`
- **Modules**: `snake_case`
- **Lifetimes**: `'a`, `'b`, single lowercase letters

### Error Handling Standards

```rust
// ✅ Preferred: Custom error types with thiserror
use thiserror::Error;

#[derive(Error, Debug)]
pub enum DatabaseError {
    #[error("Connection failed to database")]
    ConnectionFailed,

    #[error("Schema discovery failed: {0}")]
    SchemaDiscoveryFailed(String),

    #[error("Query execution failed")]
    QueryFailed(#[from] sqlx::Error),

    #[error("Serialization failed")]
    SerializationFailed(#[from] serde_json::Error),
}

pub type Result<T> = std::result::Result<T, DatabaseError>;

// ✅ Proper error propagation with context
async fn collect_schema(url: &str) -> Result<Schema> {
    let pool = create_connection_pool(url)
        .await
        .map_err(|_| DatabaseError::ConnectionFailed)?;

    let tables = fetch_tables(&pool)
        .await
        .map_err(|e| DatabaseError::SchemaDiscoveryFailed(e.to_string()))?;

    Ok(Schema { tables })
}
```

### Database Operations

```rust
// ✅ Correct: Parameterized queries only
async fn get_table_info(pool: &PgPool, table_name: &str) -> Result<TableInfo> {
    let query = r#"
        SELECT table_name, table_schema, table_type
        FROM information_schema.tables
        WHERE table_name = $1
    "#;

    let row = sqlx::query_as::<_, TableInfo>(query)
        .bind(table_name)
        .fetch_one(pool)
        .await
        .map_err(DatabaseError::QueryFailed)?;

    Ok(row)
}

// ❌ Never do this: SQL injection vulnerability
async fn get_table_info_bad(pool: &PgPool, table_name: &str) -> Result<TableInfo> {
    let query = format!(
        "SELECT * FROM information_schema.tables WHERE table_name = '{}'",
        table_name
    );
    // This is vulnerable to SQL injection
}
```

### Security-Focused Patterns

```rust
// ✅ Secure: No credential exposure
#[derive(Debug)]
pub struct DatabaseConfig {
    host: String,
    port: u16,
    database: String,
    // Never log or display credentials
    username: String,
    password: String,
}

impl std::fmt::Display for DatabaseConfig {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "DatabaseConfig({}:{}@{})", self.host, self.port, self.database)
        // Intentionally omit credentials
    }
}

// ✅ Secure logging without credentials
impl DatabaseConfig {
    pub fn connection_string(&self) -> String {
        format!(
            "postgres://{}:{}@{}:{}/{}",
            self.username, self.password, self.host, self.port, self.database
        )
    }

    pub fn safe_description(&self) -> String {
        format!("Database connection to {}:{}/{}", self.host, self.port, self.database)
    }
}

// ✅ Use for logging
log::info!("Establishing {}", config.safe_description());
// ❌ Never do this
log::info!("Connecting with {}", config.connection_string());
```

### Async/Await Patterns

```rust
// ✅ Proper async patterns with error handling
use tokio::time::{timeout, Duration};

async fn collect_with_timeout(url: &str) -> Result<Schema> {
    let timeout_duration = Duration::from_secs(30);

    timeout(timeout_duration, collect_schema_internal(url))
        .await
        .map_err(|_| DatabaseError::ConnectionTimeout)?
        .map_err(DatabaseError::from)
}

async fn collect_schema_internal(url: &str) -> sqlx::Result<Schema> {
    let pool = sqlx::postgres::PgPoolOptions::new()
        .max_connections(5)
        .connect(url)
        .await?;

    let tables = collect_tables(&pool).await?;
    let columns = collect_columns(&pool).await?;

    Ok(Schema { tables, columns })
}
```

### Testing Standards

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use testcontainers::{clients, images};

    // ✅ Integration test with real database
    #[tokio::test]
    async fn test_postgres_schema_collection() {
        let docker = clients::Cli::default();
        let postgres = docker.run(images::postgres::Postgres::default());

        let port = postgres.get_host_port_ipv4(5432);
        let database_url = format!("postgres://postgres:postgres@localhost:{}/postgres", port);

        let result = collect_schema(&database_url).await;
        assert!(result.is_ok());

        let schema = result.unwrap();
        assert!(!schema.tables.is_empty());
    }

    // ✅ Security test: Verify no credentials in output
    #[tokio::test]
    async fn test_no_credentials_in_schema_output() {
        let database_url = "postgres://testuser:secretpass@localhost/testdb";
        let schema = collect_schema(database_url).await?;
        let json_output = serde_json::to_string(&schema)?;

        // Verify sensitive data is not present
        assert!(!json_output.contains("secretpass"));
        assert!(!json_output.contains("testuser:secretpass"));
        assert!(!json_output.contains("password"));
    }

    // ✅ Unit test with proper error handling
    #[test]
    fn test_database_config_display() {
        let config = DatabaseConfig {
            host: "localhost".to_string(),
            port: 5432,
            database: "testdb".to_string(),
            username: "user".to_string(),
            password: "secret".to_string(),
        };

        let display = config.to_string();
        assert!(!display.contains("secret"));
        assert!(!display.contains("user:secret"));
        assert!(display.contains("localhost:5432"));
    }
}

// ✅ Benchmark tests for performance
#[cfg(test)]
mod benchmarks {
    use super::*;
    use criterion::{black_box, criterion_group, criterion_main, Criterion};

    fn bench_schema_serialization(c: &mut Criterion) {
        let schema = create_test_schema();

        c.bench_function("schema_to_json", |b| {
            b.iter(|| serde_json::to_string(black_box(&schema)))
        });
    }

    criterion_group!(benches, bench_schema_serialization);
    criterion_main!(benches);
}
```

### Documentation Standards

```rust
/// Database schema collector for PostgreSQL databases.
///
/// This collector connects to a PostgreSQL database and extracts comprehensive
/// schema information including tables, columns, indexes, and constraints.
/// All operations are read-only and safe for production environments.
///
/// # Security
///
/// * No credentials are stored or logged
/// * All database operations are read-only
/// * Connection strings are sanitized in error messages
///
/// # Examples
///
/// ```rust
/// use dbsurveyor_shared::PostgresCollector;
///
/// let collector = PostgresCollector::new("postgres://user:pass@localhost/db").await?;
/// let schema = collector.collect_schema().await?;
/// println!("Found {} tables", schema.tables.len());
/// ```
pub struct PostgresCollector {
    pool: PgPool,
}

impl PostgresCollector {
    /// Creates a new PostgreSQL collector with the given connection string.
    ///
    /// # Arguments
    ///
    /// * `database_url` - PostgreSQL connection string
    ///
    /// # Errors
    ///
    /// Returns `DatabaseError::ConnectionFailed` if the database connection cannot be established.
    ///
    /// # Security
    ///
    /// The connection string should not be logged or stored. Use `safe_description()`
    /// for logging purposes.
    pub async fn new(database_url: &str) -> Result<Self> {
        let pool = sqlx::postgres::PgPoolOptions::new()
            .max_connections(5)
            .connect(database_url)
            .await
            .map_err(|_| DatabaseError::ConnectionFailed)?;

        Ok(Self { pool })
    }
}
```

### Cargo.toml Standards

```toml
[package]
name = "dbsurveyor-collector"
version = "0.1.0"
edition = "2021"
rust-version = "1.77"
authors = ["UncleSp1d3r"]
license = "Apache-2.0"
description = "Secure database schema collector for PostgreSQL, MySQL, and SQLite"
keywords = ["database", "schema", "security", "offline"]
categories = ["command-line-utilities", "database"]

# Security-focused dependencies
[dependencies]
# Async runtime
tokio = { version = "1.0", features = ["macros", "rt-multi-thread"] }

# Database access
sqlx = { version = "0.7", features = ["postgres", "mysql", "sqlite", "runtime-tokio-rustls", "chrono", "uuid"] }

# CLI framework
clap = { version = "4.0", features = ["derive", "env"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Logging (no external reporting)
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Encryption
aes-gcm = "0.10"
argon2 = "0.5"
rand = "0.8"

[dev-dependencies]
# Testing with real databases
testcontainers = "0.15"
criterion = "0.5"

# Security auditing
tokio-test = "0.4"

[[bench]]
name = "schema_collection"
harness = false

[profile.release]
# Security-optimized release profile
lto = true
codegen-units = 1
panic = "abort"
strip = "symbols"

[profile.dev]
# Development profile with security checks
debug = true
overflow-checks = true
```

### Module Organization

```rust
// src/lib.rs - Library root
//! DBSurveyor Shared Library
//!
//! This library provides common functionality for database schema collection
//! and processing across PostgreSQL, MySQL, and SQLite databases.

pub mod collector;
pub mod schema;
pub mod encryption;
pub mod error;

pub use collector::{PostgresCollector, MySqlCollector, SqliteCollector};
pub use schema::{Schema, Table, Column, Index, Constraint};
pub use error::{DatabaseError, Result};

// src/collector/mod.rs - Database collectors
pub mod postgres;
pub mod mysql;
pub mod sqlite;

pub use postgres::PostgresCollector;
pub use mysql::MySqlCollector;
pub use sqlite::SqliteCollector;

/// Trait for database schema collectors
#[async_trait::async_trait]
pub trait SchemaCollector {
    /// Collect comprehensive schema information
    async fn collect_schema(&self) -> crate::Result<Schema>;

    /// Test database connectivity without collecting data
    async fn test_connection(&self) -> crate::Result<()>;

    /// Get a safe description for logging (no credentials)
    fn safe_description(&self) -> String;
}
```

### Dependency Security

```toml
# cargo-deny.toml - Security policy
[bans]
# Deny unsafe dependencies
deny = [
    { name = "openssl-sys", version = "*" },  # Use rustls instead
    { name = "native-tls", version = "*" },   # Use rustls instead
]

[licenses]
# Only allow permissive licenses
allow = ["MIT", "Apache-2.0", "BSD-3-Clause"]

[advisories]
# Security vulnerability database
db-path = "~/.cargo/advisory-db"
db-urls = ["https://github.com/rustsec/advisory-db"]
vulnerability = "deny"
unmaintained = "warn"
yanked = "deny"
notice = "warn"
```

### Performance Patterns

```rust
// ✅ Efficient database operations
use sqlx::Row;

async fn collect_tables_efficient(pool: &PgPool) -> Result<Vec<Table>> {
    let query = r#"
        SELECT
            t.table_name,
            t.table_schema,
            t.table_type,
            obj_description(c.oid) as table_comment
        FROM information_schema.tables t
        LEFT JOIN pg_class c ON c.relname = t.table_name
        WHERE t.table_schema NOT IN ('information_schema', 'pg_catalog')
        ORDER BY t.table_schema, t.table_name
    "#;

    let rows = sqlx::query(query)
        .fetch_all(pool)
        .await
        .map_err(DatabaseError::QueryFailed)?;

    let tables = rows
        .into_iter()
        .map(|row| Table {
            name: row.get("table_name"),
            schema: row.get("table_schema"),
            table_type: row.get("table_type"),
            comment: row.get("table_comment"),
        })
        .collect();

    Ok(tables)
}

// ✅ Memory-efficient streaming for large datasets
use futures::StreamExt;

async fn collect_large_table_data(pool: &PgPool, table_name: &str) -> Result<Vec<Row>> {
    let query = format!("SELECT * FROM {}", table_name); // Note: table_name should be validated

    let mut stream = sqlx::query(&query).fetch(pool);
    let mut results = Vec::new();

    while let Some(row) = stream.next().await {
        let row = row.map_err(DatabaseError::QueryFailed)?;
        results.push(row);

        // Prevent excessive memory usage
        if results.len() > 10_000 {
            log::warn!("Table {} has more than 10k rows, truncating", table_name);
            break;
        }
    }

    Ok(results)
}
```

## Key Principles

1. **Security First**: Every API must be secure by default
2. **Zero Warnings**: All clippy warnings must be addressed
3. **Comprehensive Testing**: Unit, integration, and security tests
4. **Clear Documentation**: All public APIs documented
5. **Performance Aware**: Efficient database operations
6. **Error Context**: Rich error information without exposing credentials
7. **Offline Compatible**: No external dependencies at runtime
