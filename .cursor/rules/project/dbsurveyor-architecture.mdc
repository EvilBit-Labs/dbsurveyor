---
globs: **/*.rs,**/Cargo.toml,**/*.md
alwaysApply: true
---

# DBSurveyor Architecture Standards

## Project Architecture

### Core Philosophy

DBSurveyor is built around three fundamental principles:

1. **Security-First**: Every design decision prioritizes security and privacy
2. **Offline-Capable**: Zero external dependencies after database connection
3. **Database-Agnostic**: Unified interface across PostgreSQL, MySQL, and SQLite

### High-Level Architecture

```text
┌─────────────────────────────────────────────────────────────────┐
│                          DBSurveyor                            │
│                                                                 │
│  ┌─────────────┐    ┌──────────────────┐    ┌─────────────────┐ │
│  │     CLI     │───▶│  Schema Collector │───▶│ Output Generator│ │
│  │             │    │                  │    │                 │ │
│  │ • Args      │    │ • PostgreSQL     │    │ • Markdown      │ │
│  │ • Config    │    │ • MySQL          │    │ • JSON          │ │
│  │ • Security  │    │ • SQLite         │    │ • Encrypted     │ │
│  └─────────────┘    └──────────────────┘    └─────────────────┘ │
│                                │                                │
│                                ▼                                │
│                     ┌──────────────────┐                       │
│                     │  Security Layer   │                       │
│                     │                  │                       │
│                     │ • Encryption     │                       │
│                     │ • Sanitization   │                       │
│                     │ • Access Control │                       │
│                     └──────────────────┘                       │
└─────────────────────────────────────────────────────────────────┘
```

## Module Organization

### Crate Structure

```text
dbsurveyor/
├── Cargo.toml                 # Workspace configuration
├── crates/
│   ├── dbsurveyor-shared/     # Core library
│   │   ├── src/
│   │   │   ├── lib.rs         # Public API exports
│   │   │   ├── models/        # Data structures
│   │   │   ├── collectors/    # Database-specific collectors
│   │   │   ├── encryption/    # Security and encryption
│   │   │   ├── output/        # Documentation generators
│   │   │   └── error.rs       # Error types
│   │   └── Cargo.toml
│   └── dbsurveyor-cli/        # Command-line interface
│       ├── src/
│       │   ├── main.rs        # CLI entry point
│       │   ├── args.rs        # Argument parsing
│       │   ├── config.rs      # Configuration management
│       │   └── commands/      # CLI commands
│       └── Cargo.toml
├── docs/                      # Project documentation
├── examples/                  # Usage examples
├── tests/                     # Integration tests
└── benches/                   # Performance benchmarks
```

### Module Responsibilities

#### `dbsurveyor-shared` (Core Library)

**Purpose**: Provides database-agnostic schema collection and processing capabilities.

```rust
// lib.rs - Public API surface
pub mod models;
pub mod collectors;
pub mod encryption;
pub mod output;
pub mod error;

// Re-export key types for ergonomic API
pub use error::*;
pub use models::{DatabaseSchema, DatabaseType, Table, Column};
pub use collectors::{PostgresCollector, MySqlCollector, SqliteCollector};
```

**Key Modules**:

- `models/`: Unified data structures representing database schemas
- `collectors/`: Database-specific schema extraction implementations
- `encryption/`: AES-GCM encryption for sensitive data protection
- `output/`: Documentation generators (Markdown, JSON, encrypted formats)
- `error.rs`: Comprehensive error types with security-conscious messages

#### `dbsurveyor-cli` (Command-Line Interface)

**Purpose**: Provides user-friendly CLI with secure credential handling.

```rust
// main.rs - CLI entry point
use clap::Parser;
use dbsurveyor_shared::*;

#[derive(Parser)]
#[command(name = "dbsurveyor")]
#[command(about = "Secure database schema documentation tool")]
struct Cli {
        #[command(subcommand)]
        command: Commands,
}

#[derive(Subcommand)]
enum Commands {
        Postgres(PostgresCommand),
        Mysql(MysqlCommand),
        Sqlite(SqliteCommand),
}
```

## Data Flow Architecture

### Schema Collection Pipeline

```text
1. Connection Establishment
    ┌─────────────────────┐
    │ Connection String   │ → Sanitize credentials
    │ "postgres://..."    │   Remove from logs/errors
    └─────────────────────┘
                        │
                        ▼
2. Database Introspection
    ┌─────────────────────┐
    │ System Tables       │ → Read-only queries
    │ information_schema  │   Minimal privileges
    │ pg_catalog, etc.    │   Timeout protection
    └─────────────────────┘
                        │
                        ▼
3. Schema Processing
    ┌─────────────────────┐
    │ Raw Schema Data     │ → Normalize structure
    │ Tables, columns     │   Validate data types
    │ Indexes, constraints│   Calculate metadata
    └─────────────────────┘
                        │
                        ▼
4. Security Layer
    ┌─────────────────────┐
    │ Unified Schema      │ → Optional encryption
    │ DatabaseSchema      │   Credential sanitization
    │ struct              │   Access control
    └─────────────────────┘
                        │
                        ▼
5. Output Generation
    ┌─────────────────────┐
    │ Documentation       │ → Multiple formats
    │ Markdown, JSON      │   Template-based
    │ Encrypted binary    │   Offline-capable
    └─────────────────────┘
```

### Error Handling Architecture

```rust
// Comprehensive error handling with security focus
#[derive(Debug, thiserror::Error)]
pub enum DbSurveyorError {
        #[error("Database connection failed")]
        Connection(#[from] ConnectionError),

        #[error("Schema collection failed")]
        Collection(#[from] CollectionError),

        #[error("Encryption operation failed")]
        Encryption(#[from] EncryptionError),

        #[error("Output generation failed")]
        Output(#[from] OutputError),
}

// Security-conscious error messages
impl ConnectionError {
        pub fn sanitized_message(&self) -> String {
                // Remove credentials from error messages
                match self {
                        ConnectionError::DatabaseUnreachable { host, port, .. } => {
                                format!("Cannot connect to database at {}:{}", host, port)
                        }
                        ConnectionError::AuthenticationFailed => {
                                "Invalid credentials".to_string() // No specifics
                        }
                        ConnectionError::Timeout { duration } => {
                                format!("Connection timed out after {:?}", duration)
                        }
                }
        }
}
```

## Database Adapter Architecture

### Collector Trait Design

```rust
/// Unified interface for database schema collection
#[async_trait]
pub trait SchemaCollector {
        type Error: std::error::Error + Send + Sync + 'static;

        /// Create a new collector with connection string
        async fn new(connection_string: &str) -> Result<Self, Self::Error>
        where
                Self: Sized;

        /// Collect complete schema information
        async fn collect_schema(&self) -> Result<DatabaseSchema, Self::Error>;

        /// Test database connectivity
        async fn test_connection(&self) -> Result<(), Self::Error>;

        /// Get database metadata
        async fn get_metadata(&self) -> Result<DatabaseMetadata, Self::Error>;
}
```

### Database-Specific Implementations

```rust
// PostgreSQL Collector
pub struct PostgresCollector {
        pool: PgPool,
        config: PostgresConfig,
}

impl PostgresCollector {
        // PostgreSQL-specific schema queries
        const TABLES_QUERY: &'static str = r#"
                SELECT
                        table_name,
                        table_schema,
                        table_type,
                        table_comment
                FROM information_schema.tables
                WHERE table_schema NOT IN ('information_schema', 'pg_catalog')
                ORDER BY table_schema, table_name
        "#;

        const COLUMNS_QUERY: &'static str = r#"
                SELECT
                        table_name,
                        column_name,
                        data_type,
                        is_nullable,
                        column_default,
                        character_maximum_length
                FROM information_schema.columns
                WHERE table_schema = $1
                ORDER BY table_name, ordinal_position
        "#;
}
```

## Security Architecture

### Credential Management

```rust
// Secure credential handling
pub struct ConnectionConfig {
        host: String,
        port: u16,
        database: String,
        // Credentials are never stored in structs
        // Always passed as parameters and immediately consumed
}

impl ConnectionConfig {
        /// Parse connection string without storing credentials
        pub fn from_url(url: &str) -> Result<(Self, Credentials), ConnectionError> {
                let parsed = Url::parse(url)?;

                let config = Self {
                        host: parsed.host_str().unwrap_or("localhost").to_string(),
                        port: parsed.port().unwrap_or(5432),
                        database: parsed.path().trim_start_matches('/').to_string(),
                };

                let credentials = Credentials {
                        username: parsed.username().to_string(),
                        password: parsed.password().map(String::from),
                };

                Ok((config, credentials))
        }
}

impl Drop for Credentials {
        fn drop(&mut self) {
                // Zero out sensitive data
                self.username.zeroize();
                if let Some(ref mut password) = self.password {
                        password.zeroize();
                }
        }
}
```

### Encryption Architecture

```rust
// AES-GCM encryption for schema data
pub struct EncryptedData {
        pub algorithm: String,           // "AES-GCM-256"
        pub nonce: Vec<u8>,             // 96-bit random nonce
        pub ciphertext: Vec<u8>,        // Encrypted data
        pub tag: Vec<u8>,               // Authentication tag
        pub kdf_params: Option<KdfParams>, // Key derivation parameters
}

pub async fn encrypt_schema_data(
        plaintext: &[u8],
        key: Option<&EncryptionKey>,
) -> Result<EncryptedData, EncryptionError> {
        // Use provided key or derive from system entropy
        let encryption_key = match key {
                Some(k) => k.clone(),
                None => EncryptionKey::derive_from_entropy().await?,
        };

        // Generate random nonce for each encryption
        let nonce = generate_random_nonce()?;

        // Encrypt with AES-GCM-256
        let cipher = Aes256Gcm::new(&encryption_key.as_bytes());
        let ciphertext = cipher.encrypt(&nonce, plaintext)?;

        Ok(EncryptedData {
                algorithm: "AES-GCM-256".to_string(),
                nonce: nonce.to_vec(),
                ciphertext,
                tag: vec![], // Included in ciphertext for AES-GCM
                kdf_params: Some(encryption_key.kdf_params()),
        })
}
```

## Performance Architecture

### Connection Pooling

```rust
// Efficient connection management
pub struct CollectorPool {
        postgres_pools: HashMap<String, PgPool>,
        mysql_pools: HashMap<String, MySqlPool>,
        sqlite_pools: HashMap<String, SqlitePool>,
        config: PoolConfig,
}

impl CollectorPool {
        pub async fn get_postgres_collector(
                &mut self,
                connection_string: &str,
        ) -> Result<PostgresCollector, ConnectionError> {
                let pool = match self.postgres_pools.get(connection_string) {
                        Some(pool) => pool.clone(),
                        None => {
                                let pool = PgPoolOptions::new()
                                        .max_connections(self.config.max_connections)
                                        .connect_timeout(self.config.connect_timeout)
                                        .connect(connection_string)
                                        .await?;

                                self.postgres_pools.insert(connection_string.to_string(), pool.clone());
                                pool
                        }
                };

                Ok(PostgresCollector::from_pool(pool))
        }
}
```

### Memory Management

```rust
// Streaming schema processing for large databases
pub struct StreamingCollector<T> {
        inner: T,
        batch_size: usize,
        memory_limit: usize,
}

impl<T: SchemaCollector> StreamingCollector<T> {
        pub async fn collect_schema_streaming(
                &self,
                mut writer: impl AsyncWrite + Unpin,
        ) -> Result<(), T::Error> {
                // Process tables in batches to limit memory usage
                let table_count = self.inner.count_tables().await?;
                let batch_count = (table_count + self.batch_size - 1) / self.batch_size;

                for batch_index in 0..batch_count {
                        let offset = batch_index * self.batch_size;
                        let batch_tables = self.inner
                                .collect_tables_batch(offset, self.batch_size)
                                .await?;

                        // Stream each batch to output
                        let batch_json = serde_json::to_vec(&batch_tables)?;
                        writer.write_all(&batch_json).await?;

                        // Force garbage collection of batch data
                        drop(batch_tables);
                }

                Ok(())
        }
}
```

## Testing Architecture

### Test Organization

```text
tests/
├── integration/
│   ├── postgres_integration.rs    # PostgreSQL end-to-end tests
│   ├── mysql_integration.rs       # MySQL end-to-end tests
│   ├── sqlite_integration.rs      # SQLite end-to-end tests
│   └── common/
│       ├── mod.rs                 # Shared test utilities
│       ├── testcontainers.rs     # Docker test containers
│       └── fixtures/              # Test data
├── security/
│   ├── credential_protection.rs   # Credential sanitization tests
│   ├── encryption_tests.rs        # Cryptography validation
│   └── offline_operation.rs       # Network isolation tests
└── performance/
        ├── large_schema_tests.rs      # Performance with large schemas
        ├── memory_usage_tests.rs      # Memory consumption validation
        └── concurrent_access.rs       # Thread safety tests
```

### Security Testing

```rust
// Comprehensive security test suite
#[cfg(test)]
mod security_tests {
        use super::*;

        #[tokio::test]
        async fn test_credential_sanitization() {
                let connection_string = "postgres://admin:supersecret@prod.db/main";

                // Simulate connection failure
                let error = PostgresCollector::new(connection_string).await.unwrap_err();
                let error_message = format!("{}", error);

                // Verify credentials are not in error messages
                assert!(!error_message.contains("supersecret"));
                assert!(!error_message.contains("admin:supersecret"));
                assert!(error_message.contains("prod.db")); // Host is OK to show
        }

        #[tokio::test]
        async fn test_encrypted_serialization() {
                let schema = create_test_schema();
                let json_data = serde_json::to_vec(&schema)?;

                let encrypted = encrypt_schema_data(&json_data, None).await?;
                let decrypted = decrypt_schema_data(&encrypted).await?;

                assert_eq!(json_data, decrypted);
                assert_ne!(json_data, encrypted.ciphertext); // Ensure encryption
        }
}
```

## Configuration Architecture

### Configuration Management

```rust
// Hierarchical configuration system
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DbSurveyorConfig {
        pub database: DatabaseConfig,
        pub security: SecurityConfig,
        pub output: OutputConfig,
        pub performance: PerformanceConfig,
}

impl DbSurveyorConfig {
        /// Load configuration from multiple sources
        pub fn load() -> Result<Self, ConfigError> {
                let mut config = Config::builder()
                        // Default settings
                        .add_source(config::File::from_str(DEFAULT_CONFIG, FileFormat::Toml))
                        // System-wide config
                        .add_source(config::File::with_name("/etc/dbsurveyor/config").required(false))
                        // User config
                        .add_source(config::File::with_name("~/.config/dbsurveyor/config").required(false))
                        // Project config
                        .add_source(config::File::with_name("dbsurveyor.toml").required(false))
                        // Environment variables
                        .add_source(config::Environment::with_prefix("DBSURVEYOR"))
                        .build()?;

                config.try_deserialize()
        }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SecurityConfig {
        pub encryption_enabled: bool,
        pub key_derivation_iterations: u32,
        pub sanitize_output: bool,
        pub offline_mode: bool,
}
```

This architecture ensures DBSurveyor maintains its security-first principles while providing a clean, maintainable, and extensible codebase that can grow with future requirements.
